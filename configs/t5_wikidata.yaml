experiment:
  name: env(T5_MODEL:t5-small)-wikidata

seed: 22

input_tokenizer: file(tokenizers/env(T5_TOKENIZER:t5).yaml)
output_tokenizer: file(tokenizers/env(T5_TOKENIZER:t5)_output.yaml)
add_prefix_space: true

model: file(models/t5.yaml)

train:
  peft: file(peft/env(PEFT:none).yaml)
  compile: env(COMPILE:false)
  precision: env(PRECISION:fp32)
  clip_grad_norm: env(CLIP_GRAD_NORM:1.0)
  num_epochs: env(NUM_EPOCHS:1)
  eval_interval: eval(1 / env(EVAL_N:4))
  log_interval: eval(1 / env(LOG_N:100))
  step_interval: eval(1 / env(STEP_N:100000))
  distributed:
    type: env(DIST_TYPE:DDP)
    strategy: env(DIST_SHARD:NO_SHARD)
    offload: env(DIST_OFFLOAD:false)
    prefetch: env(DIST_PREFETCH:true)
    shard_size: env(DIST_SHARD_SIZE:null)
  loss:
    type: sequence
    loss:
      type: cross_entropy
      ignore_index: -1
      label_smoothing: env(LABEL_SMOOTHING:0.0)
  optimizer:
    type: adamw
    lr: env(LR:0.00005)
    weight_decay: env(WEIGHT_DECAY:0.01)
    optim_bits: eval(8 if "env(USE_8BIT:false)" == "true" else 32)
  lr_scheduler:
    type: constant_with_warmup
    warmup_steps: env(WARMUP:0.05)
  data:
    strategy: weighted
    shuffle: true
    sort: env(SORT:false)
    limit: env(TRAIN_LIMIT:null)
    max_length: env(MAX_LENGTH:512)
    buffer_size: env(BUFFER_SIZE:512)
    prefetch_factor: env(PREFETCH_FACTOR:512)
    num_threads: eval(env(THREADS:None) or len(os.sched_getaffinity(0)) // 2)
    batch_limit: eval(env(MAX_LENGTH:512) * env(BATCH_LIMIT:8) if "env(BATCH_LIMIT_TYPE:batch_size)" == "padded_item_size" else env(BATCH_LIMIT:8))
    batch_limit_type: env(BATCH_LIMIT_TYPE:batch_size)
    pipeline:
      preprocessing: file(preprocessings/clean_and_normalize.yaml)
      tokenizer: file(tokenizers/env(T5_TOKENIZER:t5).yaml)
      labeling:
        type: generation
        tokenizer: file(tokenizers/env(T5_TOKENIZER:t5)_output.yaml)
        generation:
          type: target_only
      postprocessing: file(postprocessings/clip.yaml)
    sources: 
      - file(data/lcquad.yaml)
      - file(data/mcwq.yaml)
      - file(data/qald10.yaml)
      - file(data/qawiki.yaml)
      # - file(data/wikidata_simplequestions.yaml)
val:
  data: env(VAL_LIMIT:500)
  cooldown: env(COOLDOWN:0.05)
  benchmark:
    limit: env(BENCHMARK_LIMIT:128)
    entity_index: data/prefix-index/wikidata-llama-entities.bin
    property_index: data/prefix-index/wikidata-llama-properties.bin
    search: env(SEARCH:beam)
    beam_width: env(BEAM_WIDTH:4)
    batch_size: eval(env(BATCH_LIMIT:8) // env(BEAM_WIDTH:4))
    kg: wikidata
    log_n_samples: env(BENCHMARK_LOG_N:8)
