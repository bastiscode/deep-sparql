experiment:
  name: env(GPT2_MODEL:gpt2)-wdsimple

seed: 22

input_tokenizer: file(tokenizers/env(GPT2_TOKENIZER:gpt2).yaml)
output_tokenizer: file(tokenizers/env(GPT2_TOKENIZER:gpt2).yaml)

model: file(models/gpt2.yaml)

train:
  peft: file(peft/env(PEFT:none).yaml)
  peft_task: lm
  mixed_precision: env(MIXED_PRECISION:false)
  mixed_precision_dtype: env(MIXED_PRECISION_DTYPE:bfp16)
  clip_grad_norm: env(CLIP_GRAD_NORM:1.0)
  num_epochs: env(NUM_EPOCHS:1)
  eval_interval: eval(1 / env(EVAL_N:10))
  log_interval: eval(1 / env(LOG_N:100))
  step_interval: eval(1 / env(STEP_N:100000))
  loss:
    type: sequence
    loss:
      type: cross_entropy
      ignore_index: -1
      label_smoothing: env(LABEL_SMOOTHING:0.0)
  optimizer:
    type: adamw
    lr: env(LR:0.00005)
    weight_decay: env(WEIGHT_DECAY:0.01)
  lr_scheduler:
    type: cont_sqrt_with_warmup
    warmup_steps: eval(40454 // (100 * env(BATCH_LIMIT:8)))
  data:
    strategy: weighted
    shuffle: true
    sort: env(SORT:false)
    limit: env(TRAIN_LIMIT:null)
    max_length: env(MAX_LENGTH:512)
    buffer_size: env(BUFFER_SIZE:512)
    prefetch_factor: env(PREFETCH_FACTOR:512)
    num_threads: eval(env(THREADS:None) or len(os.sched_getaffinity(0)) // 2)
    batch_limit: eval(env(MAX_LENGTH:512) * env(BATCH_LIMIT:8) if "env(BATCH_LIMIT_TYPE:padded_item_size)" == "padded_item_size" else env(BATCH_LIMIT:8))
    batch_limit_type: env(BATCH_LIMIT_TYPE:padded_item_size)
    mask_prefix: env(MASK_PREFIX:true)
    pipeline:
      preprocessing: file(preprocessings/clean_and_normalize.yaml)
      tokenizer: file(tokenizers/env(GPT2_TOKENIZER:gpt2)_train.yaml)
      labeling:
        tokenizer: file(tokenizers/env(GPT2_TOKENIZER:gpt2)_train.yaml)
        type: generation
        generation:
          type: input_and_target
          separator: pad(>>;1;1; )
      postprocessing: file(postprocessings/clip.yaml)
    sources: 
      - file(data/env(DATA_SOURCES:wikidata_simplequestions).yaml)
val:
  # cooldown: env(COOLDOWN:0.05)
  data: 
    - file(data/env(DATA_SOURCES:wikidata_simplequestions_val).yaml)
  benchmark:
    limit: env(BENCHMARK_LIMIT:500)
    entity_index: data/prefix-index/wikidata-gpt2-entities.bin
    property_index: data/prefix-index/wikidata-gpt2-properties.bin
    search: env(SEARCH:beam)
    beam_width: env(BEAM_WIDTH:5)
    kg: wikidata
    log_n_samples: env(BENCHMARK_LOG_N:8)
